name: Build Model and Predict (Commit outputs)

on:
  workflow_dispatch:
    inputs:
      week:
        description: "CFB Week number (e.g., 5)"
        required: true
        default: "5"
      ref:
        description: "Branch or ref to commit to (default: current)"
        required: false
        default: ""
  push:
    branches:
      - main
      - fix/**
    paths:
      - "docs/input/**"
      - "scripts/**"
      - "data/raw/cfbd/**"
      - "requirements.txt"

permissions:
  contents: write

jobs:
  build-and-predict:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    concurrency:
      group: build-predict-${{ github.ref }}
      cancel-in-progress: false
    env:
      CFBD_API_KEY: ${{ secrets.CFBD_API_KEY }}
      PYTHONUNBUFFERED: "1"
      WEEK: ${{ github.event.inputs.week }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.inputs.ref || github.ref }}

      - name: Ensure raw data exists
        run: |
          if [ ! -f data/raw/cfbd/cfb_schedule.csv ]; then
            echo "::error::data/raw/cfbd/cfb_schedule.csv not found. Run the 'Fetch CFBD Data' workflow first."
            exit 1
          fi

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # Compute a deterministic cache key from raw CSVs and scripts
      - name: Compute cache key
        id: ck
        shell: bash
        run: |
          set -euo pipefail
          tmpfile=$(mktemp)
          if [ -d data/raw/cfbd ]; then
            find data/raw/cfbd -type f -name '*.csv' -print0 | sort -z | xargs -0 sha256sum >> "$tmpfile" || true
          fi
          if [ -d scripts ]; then
            find scripts -type f -name '*.py' -print0 | sort -z | xargs -0 sha256sum >> "$tmpfile" || true
          fi
          if [ -f requirements.txt ]; then
            sha256sum requirements.txt >> "$tmpfile"
          fi
          key=$(sha256sum "$tmpfile" | cut -c1-16)
          echo "key=$key" >> "$GITHUB_OUTPUT"
          echo "Cache key: $key"

      # Restore derived dataset from cache if possible
      - name: Restore derived cache
        id: cache-derived
        uses: actions/cache@v4
        with:
          path: |
            data/derived
          key: train-${{ steps.ck.outputs.key }}

      - name: Check if derived exists
        id: has-derived
        shell: bash
        run: |
          if [ -f data/derived/training.parquet ]; then
            echo "present=true" >> "$GITHUB_OUTPUT"
          else
            echo "present=false" >> "$GITHUB_OUTPUT"
          fi

      # Build dataset only if no cached version
      - name: Build dataset (chunked/streaming)
        if: steps.has-derived.outputs.present == 'false'
        run: python -m scripts.build_dataset

      # Save derived dataset back to cache
      - name: Save derived cache
        if: steps.has-derived.outputs.present == 'false'
        uses: actions/cache@v4
        with:
          path: |
            data/derived
          key: train-${{ steps.ck.outputs.key }}

      # Train the model
      - name: Train model
        run: python -m scripts.train_model

      # Predict this week's games
      - name: Predict games for week
        run: |
          W="${WEEK:-5}"
          echo "Predicting Week ${W}"
          python -m scripts.predict --week "${W}"

      # Always commit predictions.json and train_meta.json
      - name: Commit and push predictions/meta
        shell: bash
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A docs/data/predictions.json docs/data/train_meta.json
          # Commit even if nothing changed; '|| true' prevents failure on no-op commit
          git commit -m "chore(predictions): update Week ${WEEK}" || true
          git push origin "${{ github.event.inputs.ref || github.ref_name }}"

      - name: List outputs (for debugging)
        run: ls -l docs/data || true

              - name: Commit and push predictions/meta
        shell: bash
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A docs/data/predictions.json docs/data/train_meta.json docs/data/debug_predict.json
          git commit -m "chore(predictions): update Week ${WEEK}" || true
          git push origin "${{ github.event.inputs.ref || github.ref_name }}"

